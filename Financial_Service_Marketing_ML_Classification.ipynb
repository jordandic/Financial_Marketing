{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Bank Data\n",
    "<b>Goal:</b> Using the bank-additional-full.csv file, correctly predict whether or not a customer will subscribe to a loan deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive information for the study and the dataset:\n",
    "<b>Link:</b> http://archive.ics.uci.edu/ml/datasets/Bank+Marketing <br>\n",
    "<br><b>Study Implications:</b> There are two datasets containing all the instances. bank-full.csv is the chosen one to develop our model since it focuses on information which is less dependent on macro-economic factors. The reasoning behind this is that macro-economic factors will likely dictate how much the bank should scale up or down marketing spend, but it should not be the basis for determining who should be included in the target market. Macro-economic factors are relatively unpredictable and shouldn't necessarily be the basis of developing a target market in any company's overall marketing strategy. Instead, for the purposes of this study, only personal demographic information is used. Furthermore, other demographic information, like 'job' and 'loan,' may be sufficient in reflecting the current implications of the macro-environment on the individual at the micro-level, which is what this study focuses on. In a regression model, the macro-level factors for social and economic context would be included. The ultimate implication of this classification study is to determine which customers are most likely to subscribe to a loan deposit, and therefore how the company ought to select its target market, and how to position its loan products to that cohort. Ultimately, this study will aid the bank in developing it's marketing strategy including decisions related to product, price, place, and promotions. <br>\n",
    "<br>\n",
    "<br>\n",
    "### Data Description: \n",
    "#### Input Variables:\n",
    "><b>Demographic Variables:</b> <br>\n",
    ">1 - age (numeric)<br>\n",
    "2 - job : type of job (categorical: 'admin.','blue- collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown') <br>\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed) <br>\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown') <br>\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown') <br>\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown') <br>\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown') <br>\n",
    "><b>Last Contact from the Current Campaign Variables:</b> <br>\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')<br>\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')<br>\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')<br>\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.<br>\n",
    "><b>Other Attribute Variables:</b> <br>\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact) <br>\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted) <br>\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)<br>\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')<br>\n",
    "<br>\n",
    "#### Output variable (Target Variable):\n",
    ">16 - y - has the client subscribed a term deposit? (binary: 'yes','no') <br>\n",
    "\n",
    "#### Omitted Variables:\n",
    "><b>Social and Economic Context Variables:</b> <br>\n",
    "> - emp.var.rate: employment variation rate - quarterly indicator (numeric) <br>\n",
    "> - cons.price.idx: consumer price index - monthly indicator (numeric) <br>\n",
    "> - cons.conf.idx: consumer confidence index - monthly indicator (numeric) <br>\n",
    "> - euribor3m: euribor 3 month rate - daily indicator (numeric) <br>\n",
    "> - nr.employed: number of employees - quarterly indicator (numeric) <br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a term deposit?\n",
    ">A term deposit is a hybrid bank account and investment account. It is similar to a bond which yields a relatively low interest rate, but normally has short maturity dates compared to bonds, thereby making them more accessable as cash in the near future. Term deposits will normally mature between one month and a couple years while some bonds can mature in decades. The best example of a term deposit is a CD, or Certificate of Deposit. These instruments are very useful for banks because they provide more dependability of deposits.\n",
    "### Why is dependability of deposits important for banks?\n",
    ">Have you ever heard of a run on a bank? The Great Depression of the early 1900's was partly caused by a nationwide financial scare where everyone was trying to get their money out of the banking system at once. This was detrimental to banks, and is an issue which modern day bank regulators (OCC, Federal Reserve, and local authorities) scrutinize heavily to prevent such economic fallout from ever occurring again. Banks must keep a sufficient amount of money in reserves for both bad loan expenses (defaults) and to meet the withdrawal needs of their customers, or depositors. If there are not sufficient reserves in a bank to meet both of those requirements, and other expenses of the bank, then that bank could fail. So, besides just simply holding a sufficient amount of cash in reserves with cushion, banks can also use term deposits to ensure that those reserves are more stable. Higher quality deposits are an effective means of reducing the overall risk of a bank's loan portfolio, or balance sheet. Essentially, term deposits offer higher rates to depositors, but the catch is that the term deposit cannot be withdrawn for a period of time. If it is withdrawn early, there will be a penalty imposed. In conclusion, term deposits, or CDs, are an important way for banks to reduce risk, and it is important for them to effectively target customers who may be interested in such securities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate bank-additional-full.csv in working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install os_sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jordandick/Documents/6341 - Applied ML/project 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of files in current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rough_final_Project2_Regression_Group4_Gautam_Dick.ipynb',\n",
       " 'Financial_Service_Marketing_ML_Classification.ipynb',\n",
       " '.DS_Store',\n",
       " 'Project2_Regression_Group4_Gautam_Dick.ipynb',\n",
       " 'Intermediate-Project2_Regression_Group4_Gautam_Dick.ipynb',\n",
       " 'Financial_Service_Marketing_Classification.ipynb',\n",
       " 'bank_data_new.csv',\n",
       " 'Project2_Classification_Group4_Gautam_Dick.ipynb',\n",
       " 'Project2_Group08_Zhang_ShahabiNejad',\n",
       " '.ipynb_checkpoints',\n",
       " 'Almost_done_Classification_Project2.ipynb',\n",
       " 'bank-additional-full.csv',\n",
       " 'AB_NYC_2019.csv',\n",
       " 'Project2_Group08_Zhang_ShahabiNejad.zip']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis of original bank-additional-full.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(str(cwd)+'/'+'bank-additional-full.csv', sep=';', header=0)\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     36548\n",
       "yes     4640\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete this \n",
    "#df=df.sample(500)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> drop macro-related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 36094 to 20902\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   age          20000 non-null  int64 \n",
      " 1   job          20000 non-null  object\n",
      " 2   marital      20000 non-null  object\n",
      " 3   education    20000 non-null  object\n",
      " 4   default      20000 non-null  object\n",
      " 5   housing      20000 non-null  object\n",
      " 6   loan         20000 non-null  object\n",
      " 7   contact      20000 non-null  object\n",
      " 8   month        20000 non-null  object\n",
      " 9   day_of_week  20000 non-null  object\n",
      " 10  duration     20000 non-null  int64 \n",
      " 11  campaign     20000 non-null  int64 \n",
      " 12  pdays        20000 non-null  int64 \n",
      " 13  previous     20000 non-null  int64 \n",
      " 14  poutcome     20000 non-null  object\n",
      " 15  y            20000 non-null  object\n",
      "dtypes: int64(5), object(11)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "macro_lst = ['emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']\n",
    "\n",
    "for i in macro_lst:\n",
    "    df.drop([i], axis=1, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice with data imputation strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">none of the data is nan, so 5% of the values will be randomly imputed as np.nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mat = np.random.random(df.shape)<0.05\n",
    "nan_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16058"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# of nans\n",
    "n = nan_mat.sum()\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024366927260367096"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approximately 5% of the dataset will be set to nan\n",
    "n/(41188*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 36094 to 20902\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          19000 non-null  float64\n",
      " 1   job          18989 non-null  object \n",
      " 2   marital      18998 non-null  object \n",
      " 3   education    18993 non-null  object \n",
      " 4   default      18991 non-null  object \n",
      " 5   housing      18998 non-null  object \n",
      " 6   loan         19035 non-null  object \n",
      " 7   contact      18971 non-null  object \n",
      " 8   month        19068 non-null  object \n",
      " 9   day_of_week  18991 non-null  object \n",
      " 10  duration     18942 non-null  float64\n",
      " 11  campaign     18956 non-null  float64\n",
      " 12  pdays        19051 non-null  float64\n",
      " 13  previous     18991 non-null  float64\n",
      " 14  poutcome     18962 non-null  object \n",
      " 15  y            19006 non-null  object \n",
      "dtypes: float64(5), object(11)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dfn = df.mask(nan_mat)\n",
    "dfn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05018125\n"
     ]
    }
   ],
   "source": [
    "# 5% of new data frame is nan\n",
    "\n",
    "nnan = dfn.isnull().sum().sum()\n",
    "ntot = dfn.shape[1]*dfn.shape[0]\n",
    "percent_nan = nnan/ntot\n",
    "\n",
    "print(percent_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export new copy of data with 5% NaN\n",
    "><b>Named:</b> bank_data_new.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.to_csv('bank_data_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Preparation for ML Classification Algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 36094 to 20902\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          19000 non-null  float64\n",
      " 1   job          18989 non-null  object \n",
      " 2   marital      18998 non-null  object \n",
      " 3   education    18993 non-null  object \n",
      " 4   default      18991 non-null  object \n",
      " 5   housing      18998 non-null  object \n",
      " 6   loan         19035 non-null  object \n",
      " 7   contact      18971 non-null  object \n",
      " 8   month        19068 non-null  object \n",
      " 9   day_of_week  18991 non-null  object \n",
      " 10  duration     18942 non-null  float64\n",
      " 11  campaign     18956 non-null  float64\n",
      " 12  pdays        19051 non-null  float64\n",
      " 13  previous     18991 non-null  float64\n",
      " 14  poutcome     18962 non-null  object \n",
      " 15  y            19006 non-null  object \n",
      "dtypes: float64(5), object(11)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dfn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Strategy for imputing age values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admin.</th>\n",
       "      <td>32</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>fri</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue-collar</th>\n",
       "      <td>36</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>[mon, wed]</td>\n",
       "      <td>[36.0, 119.0, 136.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrepreneur</th>\n",
       "      <td>36</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housemaid</th>\n",
       "      <td>[36.0, 39.0]</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>tue</td>\n",
       "      <td>[66.0, 86.0, 126.0, 135.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>43</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>[121.0, 175.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retired</th>\n",
       "      <td>58</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-employed</th>\n",
       "      <td>30</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>[85.0, 104.0, 139.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>services</th>\n",
       "      <td>31</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>[88.0, 158.0, 178.0, 185.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>tue</td>\n",
       "      <td>[131.0, 137.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technician</th>\n",
       "      <td>34</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemployed</th>\n",
       "      <td>39</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>45</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>[94.0, 133.0, 154.0, 258.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        age  marital            education default housing  \\\n",
       "job                                                                         \n",
       "admin.                   32  married    university.degree      no     yes   \n",
       "blue-collar              36  married             basic.9y      no     yes   \n",
       "entrepreneur             36  married    university.degree      no     yes   \n",
       "housemaid      [36.0, 39.0]  married             basic.4y      no     yes   \n",
       "management               43  married    university.degree      no     yes   \n",
       "retired                  58  married             basic.4y      no     yes   \n",
       "self-employed            30  married    university.degree      no     yes   \n",
       "services                 31  married          high.school      no     yes   \n",
       "student                  24   single          high.school      no     yes   \n",
       "technician               34  married  professional.course      no     yes   \n",
       "unemployed               39  married          high.school      no     yes   \n",
       "unknown                  45  married              unknown      no     yes   \n",
       "\n",
       "              loan   contact month day_of_week                     duration  \\\n",
       "job                                                                           \n",
       "admin.          no  cellular   may         fri                           72   \n",
       "blue-collar     no  cellular   may  [mon, wed]         [36.0, 119.0, 136.0]   \n",
       "entrepreneur    no  cellular   may         thu                           85   \n",
       "housemaid       no  cellular   may         tue   [66.0, 86.0, 126.0, 135.0]   \n",
       "management      no  cellular   may         mon               [121.0, 175.0]   \n",
       "retired         no  cellular   may         wed                          188   \n",
       "self-employed   no  cellular   may         thu         [85.0, 104.0, 139.0]   \n",
       "services        no  cellular   may         thu  [88.0, 158.0, 178.0, 185.0]   \n",
       "student         no  cellular   may         tue               [131.0, 137.0]   \n",
       "technician      no  cellular   may         thu                           76   \n",
       "unemployed      no  cellular   may         thu                           76   \n",
       "unknown         no  cellular   may         mon  [94.0, 133.0, 154.0, 258.0]   \n",
       "\n",
       "               campaign  pdays  previous     poutcome   y  \n",
       "job                                                        \n",
       "admin.              1.0  999.0       0.0  nonexistent  no  \n",
       "blue-collar         1.0  999.0       0.0  nonexistent  no  \n",
       "entrepreneur        1.0  999.0       0.0  nonexistent  no  \n",
       "housemaid           1.0  999.0       0.0  nonexistent  no  \n",
       "management          1.0  999.0       0.0  nonexistent  no  \n",
       "retired             1.0  999.0       0.0  nonexistent  no  \n",
       "self-employed       1.0  999.0       0.0  nonexistent  no  \n",
       "services            1.0  999.0       0.0  nonexistent  no  \n",
       "student             1.0  999.0       0.0  nonexistent  no  \n",
       "technician          1.0  999.0       0.0  nonexistent  no  \n",
       "unemployed          1.0  999.0       0.0  nonexistent  no  \n",
       "unknown             1.0  999.0       0.0  nonexistent  no  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(dfn.groupby(dfn['job']).agg(pd.Series.mode))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> check if retired, student, and unknown represent a significant number of the total dataset to justify their use in the aggregate to impute values for the age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Retirees:\n",
      "810\n",
      "Number of Students:\n",
      "433\n",
      "Number of Unknowns:\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "# number of housemaids\n",
    "print('Number of Retirees:')\n",
    "print(dfn[dfn['job']=='retired'].shape[0])\n",
    "print('Number of Students:')\n",
    "print(dfn[dfn['job']=='student'].shape[0])\n",
    "print('Number of Unknowns:')\n",
    "print(dfn[dfn['job']=='unknown'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Informed Assumption: <br>\n",
    ">There are a sufficient number of observations representing each of the above job descriptions to make strategic data imputations where the missing values will be replaced using the mode for each category. Another assumption is that age is perhaps one of the most valuable demographic pieces of information because it is highly ocrrelated with one's stage in life, and corresponding need for term deposit type products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute np.nan values in age for the following observations: \n",
    "# housemaid, retired, student, unknown\n",
    "\n",
    "for lab, cont in dfn.iterrows():\n",
    "    age = cont['age']\n",
    "       \n",
    "    if cont['job']=='retired':age =59\n",
    "        \n",
    "    if cont['job']=='student':age=24\n",
    "    \n",
    "    if cont['job']=='unknown':age=45\n",
    "    \n",
    "        \n",
    "    if pd.isnull(cont['age'])==True: dfn.loc[lab,'age'] = age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> impute all NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the rest of the nan values in the dataset with their respective modes\n",
    "colnames = dfn.columns.to_list()\n",
    "\n",
    "for n in colnames:\n",
    "    mode = dfn[n].mode()[0]\n",
    "    dfn[n].fillna(mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            0\n",
       "job            0\n",
       "marital        0\n",
       "education      0\n",
       "default        0\n",
       "housing        0\n",
       "loan           0\n",
       "contact        0\n",
       "month          0\n",
       "day_of_week    0\n",
       "duration       0\n",
       "campaign       0\n",
       "pdays          0\n",
       "previous       0\n",
       "poutcome       0\n",
       "y              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data for ML Classification ALgorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36094</th>\n",
       "      <td>51.0</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>tue</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6343</th>\n",
       "      <td>32.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>tue</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15636</th>\n",
       "      <td>50.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>50.0</td>\n",
       "      <td>management</td>\n",
       "      <td>divorced</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>wed</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27236</th>\n",
       "      <td>34.0</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16091</th>\n",
       "      <td>38.0</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>843.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19389</th>\n",
       "      <td>34.0</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29758</th>\n",
       "      <td>34.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>mon</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30138</th>\n",
       "      <td>59.0</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>thu</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>failure</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20902</th>\n",
       "      <td>34.0</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>260.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age            job   marital            education  default housing  \\\n",
       "36094  51.0         admin.  divorced    university.degree       no      no   \n",
       "6343   32.0    blue-collar    single          high.school       no     yes   \n",
       "15636  50.0    blue-collar   married             basic.4y  unknown     yes   \n",
       "2710   50.0     management  divorced          high.school  unknown      no   \n",
       "27236  34.0     technician  divorced    university.degree       no      no   \n",
       "...     ...            ...       ...                  ...      ...     ...   \n",
       "16091  38.0  self-employed    single              unknown       no      no   \n",
       "19389  34.0         admin.    single    university.degree  unknown      no   \n",
       "29758  34.0    blue-collar   married             basic.9y       no      no   \n",
       "30138  59.0        retired  divorced  professional.course       no     yes   \n",
       "20902  34.0         admin.   married    university.degree       no      no   \n",
       "\n",
       "      loan    contact month day_of_week  duration  campaign  pdays  previous  \\\n",
       "36094   no   cellular   may         tue      91.0       1.0  999.0       0.0   \n",
       "6343    no  telephone   may         tue      72.0       2.0  999.0       0.0   \n",
       "15636  yes   cellular   jul         mon     140.0       1.0  999.0       0.0   \n",
       "2710    no  telephone   may         wed      72.0       7.0  999.0       0.0   \n",
       "27236   no   cellular   nov         fri     316.0       3.0  999.0       0.0   \n",
       "...    ...        ...   ...         ...       ...       ...    ...       ...   \n",
       "16091   no   cellular   jul         tue     843.0       8.0  999.0       0.0   \n",
       "19389   no   cellular   aug         wed     147.0       1.0  999.0       0.0   \n",
       "29758   no   cellular   apr         mon      86.0       2.0  999.0       0.0   \n",
       "30138   no   cellular   apr         thu     968.0       1.0    5.0       2.0   \n",
       "20902   no   cellular   aug         thu     260.0       6.0  999.0       0.0   \n",
       "\n",
       "          poutcome    y  \n",
       "36094  nonexistent   no  \n",
       "6343   nonexistent   no  \n",
       "15636  nonexistent   no  \n",
       "2710   nonexistent   no  \n",
       "27236  nonexistent  yes  \n",
       "...            ...  ...  \n",
       "16091  nonexistent   no  \n",
       "19389  nonexistent   no  \n",
       "29758  nonexistent   no  \n",
       "30138      failure  yes  \n",
       "20902  nonexistent   no  \n",
       "\n",
       "[20000 rows x 16 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> replace categorical columns with dummy variable columns. Categorical Columns include: <br>\n",
    "'job','marital','education','contact','month','day_of_week','poutcome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace categorical columns with dummies\n",
    "# columns to replace: \n",
    "# 'job','marital','education','contact','month','day_of_week'\n",
    "cat_vars = ['job','marital','education','contact','month','day_of_week','poutcome']\n",
    "\n",
    "fdf = dfn.copy()\n",
    "\n",
    "dfdum_list=[]\n",
    "\n",
    "for cat in cat_vars:\n",
    "    temp_df = pd.DataFrame(pd.get_dummies(dfn[cat]))\n",
    "    dfdum_list.append(temp_df)\n",
    "    \n",
    "    fdf.drop(cat, axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "dfdum_list.append(fdf)\n",
    "\n",
    "fdf = pd.concat(dfdum_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[       admin.  blue-collar  entrepreneur  housemaid  management  retired  \\\n",
       " 36094       1            0             0          0           0        0   \n",
       " 6343        0            1             0          0           0        0   \n",
       " 15636       0            1             0          0           0        0   \n",
       " 2710        0            0             0          0           1        0   \n",
       " 27236       0            0             0          0           0        0   \n",
       " ...       ...          ...           ...        ...         ...      ...   \n",
       " 16091       0            0             0          0           0        0   \n",
       " 19389       1            0             0          0           0        0   \n",
       " 29758       0            1             0          0           0        0   \n",
       " 30138       0            0             0          0           0        1   \n",
       " 20902       1            0             0          0           0        0   \n",
       " \n",
       "        self-employed  services  student  technician  unemployed  unknown  \n",
       " 36094              0         0        0           0           0        0  \n",
       " 6343               0         0        0           0           0        0  \n",
       " 15636              0         0        0           0           0        0  \n",
       " 2710               0         0        0           0           0        0  \n",
       " 27236              0         0        0           1           0        0  \n",
       " ...              ...       ...      ...         ...         ...      ...  \n",
       " 16091              1         0        0           0           0        0  \n",
       " 19389              0         0        0           0           0        0  \n",
       " 29758              0         0        0           0           0        0  \n",
       " 30138              0         0        0           0           0        0  \n",
       " 20902              0         0        0           0           0        0  \n",
       " \n",
       " [20000 rows x 12 columns],\n",
       "        divorced  married  single  unknown\n",
       " 36094         1        0       0        0\n",
       " 6343          0        0       1        0\n",
       " 15636         0        1       0        0\n",
       " 2710          1        0       0        0\n",
       " 27236         1        0       0        0\n",
       " ...         ...      ...     ...      ...\n",
       " 16091         0        0       1        0\n",
       " 19389         0        0       1        0\n",
       " 29758         0        1       0        0\n",
       " 30138         1        0       0        0\n",
       " 20902         0        1       0        0\n",
       " \n",
       " [20000 rows x 4 columns],\n",
       "        basic.4y  basic.6y  basic.9y  high.school  illiterate  \\\n",
       " 36094         0         0         0            0           0   \n",
       " 6343          0         0         0            1           0   \n",
       " 15636         1         0         0            0           0   \n",
       " 2710          0         0         0            1           0   \n",
       " 27236         0         0         0            0           0   \n",
       " ...         ...       ...       ...          ...         ...   \n",
       " 16091         0         0         0            0           0   \n",
       " 19389         0         0         0            0           0   \n",
       " 29758         0         0         1            0           0   \n",
       " 30138         0         0         0            0           0   \n",
       " 20902         0         0         0            0           0   \n",
       " \n",
       "        professional.course  university.degree  unknown  \n",
       " 36094                    0                  1        0  \n",
       " 6343                     0                  0        0  \n",
       " 15636                    0                  0        0  \n",
       " 2710                     0                  0        0  \n",
       " 27236                    0                  1        0  \n",
       " ...                    ...                ...      ...  \n",
       " 16091                    0                  0        1  \n",
       " 19389                    0                  1        0  \n",
       " 29758                    0                  0        0  \n",
       " 30138                    1                  0        0  \n",
       " 20902                    0                  1        0  \n",
       " \n",
       " [20000 rows x 8 columns],\n",
       "        cellular  telephone\n",
       " 36094         1          0\n",
       " 6343          0          1\n",
       " 15636         1          0\n",
       " 2710          0          1\n",
       " 27236         1          0\n",
       " ...         ...        ...\n",
       " 16091         1          0\n",
       " 19389         1          0\n",
       " 29758         1          0\n",
       " 30138         1          0\n",
       " 20902         1          0\n",
       " \n",
       " [20000 rows x 2 columns],\n",
       "        apr  aug  dec  jul  jun  mar  may  nov  oct  sep\n",
       " 36094    0    0    0    0    0    0    1    0    0    0\n",
       " 6343     0    0    0    0    0    0    1    0    0    0\n",
       " 15636    0    0    0    1    0    0    0    0    0    0\n",
       " 2710     0    0    0    0    0    0    1    0    0    0\n",
       " 27236    0    0    0    0    0    0    0    1    0    0\n",
       " ...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       " 16091    0    0    0    1    0    0    0    0    0    0\n",
       " 19389    0    1    0    0    0    0    0    0    0    0\n",
       " 29758    1    0    0    0    0    0    0    0    0    0\n",
       " 30138    1    0    0    0    0    0    0    0    0    0\n",
       " 20902    0    1    0    0    0    0    0    0    0    0\n",
       " \n",
       " [20000 rows x 10 columns],\n",
       "        fri  mon  thu  tue  wed\n",
       " 36094    0    0    0    1    0\n",
       " 6343     0    0    0    1    0\n",
       " 15636    0    1    0    0    0\n",
       " 2710     0    0    0    0    1\n",
       " 27236    1    0    0    0    0\n",
       " ...    ...  ...  ...  ...  ...\n",
       " 16091    0    0    0    1    0\n",
       " 19389    0    0    0    0    1\n",
       " 29758    0    1    0    0    0\n",
       " 30138    0    0    1    0    0\n",
       " 20902    0    0    1    0    0\n",
       " \n",
       " [20000 rows x 5 columns],\n",
       "        failure  nonexistent  success\n",
       " 36094        0            1        0\n",
       " 6343         0            1        0\n",
       " 15636        0            1        0\n",
       " 2710         0            1        0\n",
       " 27236        0            1        0\n",
       " ...        ...          ...      ...\n",
       " 16091        0            1        0\n",
       " 19389        0            1        0\n",
       " 29758        0            1        0\n",
       " 30138        1            0        0\n",
       " 20902        0            1        0\n",
       " \n",
       " [20000 rows x 3 columns],\n",
       "         age  default housing loan  duration  campaign  pdays  previous    y\n",
       " 36094  51.0       no      no   no      91.0       1.0  999.0       0.0   no\n",
       " 6343   32.0       no     yes   no      72.0       2.0  999.0       0.0   no\n",
       " 15636  50.0  unknown     yes  yes     140.0       1.0  999.0       0.0   no\n",
       " 2710   50.0  unknown      no   no      72.0       7.0  999.0       0.0   no\n",
       " 27236  34.0       no      no   no     316.0       3.0  999.0       0.0  yes\n",
       " ...     ...      ...     ...  ...       ...       ...    ...       ...  ...\n",
       " 16091  38.0       no      no   no     843.0       8.0  999.0       0.0   no\n",
       " 19389  34.0  unknown      no   no     147.0       1.0  999.0       0.0   no\n",
       " 29758  34.0       no      no   no      86.0       2.0  999.0       0.0   no\n",
       " 30138  59.0       no     yes   no     968.0       1.0    5.0       2.0  yes\n",
       " 20902  34.0       no      no   no     260.0       6.0  999.0       0.0   no\n",
       " \n",
       " [20000 rows x 9 columns]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 36094 to 20902\n",
      "Data columns (total 53 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   admin.               20000 non-null  uint8  \n",
      " 1   blue-collar          20000 non-null  uint8  \n",
      " 2   entrepreneur         20000 non-null  uint8  \n",
      " 3   housemaid            20000 non-null  uint8  \n",
      " 4   management           20000 non-null  uint8  \n",
      " 5   retired              20000 non-null  uint8  \n",
      " 6   self-employed        20000 non-null  uint8  \n",
      " 7   services             20000 non-null  uint8  \n",
      " 8   student              20000 non-null  uint8  \n",
      " 9   technician           20000 non-null  uint8  \n",
      " 10  unemployed           20000 non-null  uint8  \n",
      " 11  unknown              20000 non-null  uint8  \n",
      " 12  divorced             20000 non-null  uint8  \n",
      " 13  married              20000 non-null  uint8  \n",
      " 14  single               20000 non-null  uint8  \n",
      " 15  unknown              20000 non-null  uint8  \n",
      " 16  basic.4y             20000 non-null  uint8  \n",
      " 17  basic.6y             20000 non-null  uint8  \n",
      " 18  basic.9y             20000 non-null  uint8  \n",
      " 19  high.school          20000 non-null  uint8  \n",
      " 20  illiterate           20000 non-null  uint8  \n",
      " 21  professional.course  20000 non-null  uint8  \n",
      " 22  university.degree    20000 non-null  uint8  \n",
      " 23  unknown              20000 non-null  uint8  \n",
      " 24  cellular             20000 non-null  uint8  \n",
      " 25  telephone            20000 non-null  uint8  \n",
      " 26  apr                  20000 non-null  uint8  \n",
      " 27  aug                  20000 non-null  uint8  \n",
      " 28  dec                  20000 non-null  uint8  \n",
      " 29  jul                  20000 non-null  uint8  \n",
      " 30  jun                  20000 non-null  uint8  \n",
      " 31  mar                  20000 non-null  uint8  \n",
      " 32  may                  20000 non-null  uint8  \n",
      " 33  nov                  20000 non-null  uint8  \n",
      " 34  oct                  20000 non-null  uint8  \n",
      " 35  sep                  20000 non-null  uint8  \n",
      " 36  fri                  20000 non-null  uint8  \n",
      " 37  mon                  20000 non-null  uint8  \n",
      " 38  thu                  20000 non-null  uint8  \n",
      " 39  tue                  20000 non-null  uint8  \n",
      " 40  wed                  20000 non-null  uint8  \n",
      " 41  failure              20000 non-null  uint8  \n",
      " 42  nonexistent          20000 non-null  uint8  \n",
      " 43  success              20000 non-null  uint8  \n",
      " 44  age                  20000 non-null  float64\n",
      " 45  default              20000 non-null  object \n",
      " 46  housing              20000 non-null  object \n",
      " 47  loan                 20000 non-null  object \n",
      " 48  duration             20000 non-null  float64\n",
      " 49  campaign             20000 non-null  float64\n",
      " 50  pdays                20000 non-null  float64\n",
      " 51  previous             20000 non-null  float64\n",
      " 52  y                    20000 non-null  object \n",
      "dtypes: float64(5), object(4), uint8(44)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "fdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> drop unknown columns as they are less information rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 36094 to 20902\n",
      "Data columns (total 50 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   admin.               20000 non-null  uint8  \n",
      " 1   blue-collar          20000 non-null  uint8  \n",
      " 2   entrepreneur         20000 non-null  uint8  \n",
      " 3   housemaid            20000 non-null  uint8  \n",
      " 4   management           20000 non-null  uint8  \n",
      " 5   retired              20000 non-null  uint8  \n",
      " 6   self-employed        20000 non-null  uint8  \n",
      " 7   services             20000 non-null  uint8  \n",
      " 8   student              20000 non-null  uint8  \n",
      " 9   technician           20000 non-null  uint8  \n",
      " 10  unemployed           20000 non-null  uint8  \n",
      " 11  divorced             20000 non-null  uint8  \n",
      " 12  married              20000 non-null  uint8  \n",
      " 13  single               20000 non-null  uint8  \n",
      " 14  basic.4y             20000 non-null  uint8  \n",
      " 15  basic.6y             20000 non-null  uint8  \n",
      " 16  basic.9y             20000 non-null  uint8  \n",
      " 17  high.school          20000 non-null  uint8  \n",
      " 18  illiterate           20000 non-null  uint8  \n",
      " 19  professional.course  20000 non-null  uint8  \n",
      " 20  university.degree    20000 non-null  uint8  \n",
      " 21  cellular             20000 non-null  uint8  \n",
      " 22  telephone            20000 non-null  uint8  \n",
      " 23  apr                  20000 non-null  uint8  \n",
      " 24  aug                  20000 non-null  uint8  \n",
      " 25  dec                  20000 non-null  uint8  \n",
      " 26  jul                  20000 non-null  uint8  \n",
      " 27  jun                  20000 non-null  uint8  \n",
      " 28  mar                  20000 non-null  uint8  \n",
      " 29  may                  20000 non-null  uint8  \n",
      " 30  nov                  20000 non-null  uint8  \n",
      " 31  oct                  20000 non-null  uint8  \n",
      " 32  sep                  20000 non-null  uint8  \n",
      " 33  fri                  20000 non-null  uint8  \n",
      " 34  mon                  20000 non-null  uint8  \n",
      " 35  thu                  20000 non-null  uint8  \n",
      " 36  tue                  20000 non-null  uint8  \n",
      " 37  wed                  20000 non-null  uint8  \n",
      " 38  failure              20000 non-null  uint8  \n",
      " 39  nonexistent          20000 non-null  uint8  \n",
      " 40  success              20000 non-null  uint8  \n",
      " 41  age                  20000 non-null  float64\n",
      " 42  default              20000 non-null  object \n",
      " 43  housing              20000 non-null  object \n",
      " 44  loan                 20000 non-null  object \n",
      " 45  duration             20000 non-null  float64\n",
      " 46  campaign             20000 non-null  float64\n",
      " 47  pdays                20000 non-null  float64\n",
      " 48  previous             20000 non-null  float64\n",
      " 49  y                    20000 non-null  object \n",
      "dtypes: float64(5), object(4), uint8(41)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "fdf.drop('unknown', axis=1, inplace=True)\n",
    "fdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Replace ordinal columns with binary output. Columns to be mapped to ordinal ones include:<br>housing, loan, default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housing unique & mode\n",
      "['no' 'yes' 'unknown']\n",
      "yes\n",
      "loan unique & mode\n",
      "['no' 'yes' 'unknown']\n",
      "no\n",
      "default unique & mode\n",
      "['no' 'unknown' 'yes']\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "print('housing unique & mode')\n",
    "print(fdf['housing'].unique())\n",
    "hm = fdf['housing'].mode()[0]\n",
    "print(hm)\n",
    "\n",
    "print('loan unique & mode')\n",
    "print(fdf['loan'].unique())\n",
    "lm = fdf['loan'].mode()[0]\n",
    "print(lm)\n",
    "\n",
    "print('default unique & mode')\n",
    "print(fdf['default'].unique())\n",
    "dm = fdf['default'].mode()[0]\n",
    "print(dm)\n",
    "\n",
    "fdf['housing'].replace('unknown',hm, inplace=True)\n",
    "fdf['loan'].replace('unknown',lm, inplace=True)\n",
    "fdf['default'].replace('unknown',dm, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 36094 to 20902\n",
      "Data columns (total 50 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   admin.               20000 non-null  uint8  \n",
      " 1   blue-collar          20000 non-null  uint8  \n",
      " 2   entrepreneur         20000 non-null  uint8  \n",
      " 3   housemaid            20000 non-null  uint8  \n",
      " 4   management           20000 non-null  uint8  \n",
      " 5   retired              20000 non-null  uint8  \n",
      " 6   self-employed        20000 non-null  uint8  \n",
      " 7   services             20000 non-null  uint8  \n",
      " 8   student              20000 non-null  uint8  \n",
      " 9   technician           20000 non-null  uint8  \n",
      " 10  unemployed           20000 non-null  uint8  \n",
      " 11  divorced             20000 non-null  uint8  \n",
      " 12  married              20000 non-null  uint8  \n",
      " 13  single               20000 non-null  uint8  \n",
      " 14  basic.4y             20000 non-null  uint8  \n",
      " 15  basic.6y             20000 non-null  uint8  \n",
      " 16  basic.9y             20000 non-null  uint8  \n",
      " 17  high.school          20000 non-null  uint8  \n",
      " 18  illiterate           20000 non-null  uint8  \n",
      " 19  professional.course  20000 non-null  uint8  \n",
      " 20  university.degree    20000 non-null  uint8  \n",
      " 21  cellular             20000 non-null  uint8  \n",
      " 22  telephone            20000 non-null  uint8  \n",
      " 23  apr                  20000 non-null  uint8  \n",
      " 24  aug                  20000 non-null  uint8  \n",
      " 25  dec                  20000 non-null  uint8  \n",
      " 26  jul                  20000 non-null  uint8  \n",
      " 27  jun                  20000 non-null  uint8  \n",
      " 28  mar                  20000 non-null  uint8  \n",
      " 29  may                  20000 non-null  uint8  \n",
      " 30  nov                  20000 non-null  uint8  \n",
      " 31  oct                  20000 non-null  uint8  \n",
      " 32  sep                  20000 non-null  uint8  \n",
      " 33  fri                  20000 non-null  uint8  \n",
      " 34  mon                  20000 non-null  uint8  \n",
      " 35  thu                  20000 non-null  uint8  \n",
      " 36  tue                  20000 non-null  uint8  \n",
      " 37  wed                  20000 non-null  uint8  \n",
      " 38  failure              20000 non-null  uint8  \n",
      " 39  nonexistent          20000 non-null  uint8  \n",
      " 40  success              20000 non-null  uint8  \n",
      " 41  age                  20000 non-null  float64\n",
      " 42  default              20000 non-null  object \n",
      " 43  housing              20000 non-null  object \n",
      " 44  loan                 20000 non-null  object \n",
      " 45  duration             20000 non-null  float64\n",
      " 46  campaign             20000 non-null  float64\n",
      " 47  pdays                20000 non-null  float64\n",
      " 48  previous             20000 non-null  float64\n",
      " 49  y                    20000 non-null  object \n",
      "dtypes: float64(5), object(4), uint8(41)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "fdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Convert Ordinal Columns into binary where 1/0 is yes/no, respectively.<br>\n",
    "Columns to be converted: default, housing, loan, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordlst = ['default', 'housing', 'loan', 'y']\n",
    "\n",
    "for i in ordlst:\n",
    "    fdf[i].replace('yes', 1, inplace=True)\n",
    "    fdf[i].replace('no', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Dataset's variables are now in their appropriate numeric form for ML algorithms to operate on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 36094 to 20902\n",
      "Data columns (total 50 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   admin.               20000 non-null  uint8  \n",
      " 1   blue-collar          20000 non-null  uint8  \n",
      " 2   entrepreneur         20000 non-null  uint8  \n",
      " 3   housemaid            20000 non-null  uint8  \n",
      " 4   management           20000 non-null  uint8  \n",
      " 5   retired              20000 non-null  uint8  \n",
      " 6   self-employed        20000 non-null  uint8  \n",
      " 7   services             20000 non-null  uint8  \n",
      " 8   student              20000 non-null  uint8  \n",
      " 9   technician           20000 non-null  uint8  \n",
      " 10  unemployed           20000 non-null  uint8  \n",
      " 11  divorced             20000 non-null  uint8  \n",
      " 12  married              20000 non-null  uint8  \n",
      " 13  single               20000 non-null  uint8  \n",
      " 14  basic.4y             20000 non-null  uint8  \n",
      " 15  basic.6y             20000 non-null  uint8  \n",
      " 16  basic.9y             20000 non-null  uint8  \n",
      " 17  high.school          20000 non-null  uint8  \n",
      " 18  illiterate           20000 non-null  uint8  \n",
      " 19  professional.course  20000 non-null  uint8  \n",
      " 20  university.degree    20000 non-null  uint8  \n",
      " 21  cellular             20000 non-null  uint8  \n",
      " 22  telephone            20000 non-null  uint8  \n",
      " 23  apr                  20000 non-null  uint8  \n",
      " 24  aug                  20000 non-null  uint8  \n",
      " 25  dec                  20000 non-null  uint8  \n",
      " 26  jul                  20000 non-null  uint8  \n",
      " 27  jun                  20000 non-null  uint8  \n",
      " 28  mar                  20000 non-null  uint8  \n",
      " 29  may                  20000 non-null  uint8  \n",
      " 30  nov                  20000 non-null  uint8  \n",
      " 31  oct                  20000 non-null  uint8  \n",
      " 32  sep                  20000 non-null  uint8  \n",
      " 33  fri                  20000 non-null  uint8  \n",
      " 34  mon                  20000 non-null  uint8  \n",
      " 35  thu                  20000 non-null  uint8  \n",
      " 36  tue                  20000 non-null  uint8  \n",
      " 37  wed                  20000 non-null  uint8  \n",
      " 38  failure              20000 non-null  uint8  \n",
      " 39  nonexistent          20000 non-null  uint8  \n",
      " 40  success              20000 non-null  uint8  \n",
      " 41  age                  20000 non-null  float64\n",
      " 42  default              20000 non-null  int64  \n",
      " 43  housing              20000 non-null  int64  \n",
      " 44  loan                 20000 non-null  int64  \n",
      " 45  duration             20000 non-null  float64\n",
      " 46  campaign             20000 non-null  float64\n",
      " 47  pdays                20000 non-null  float64\n",
      " 48  previous             20000 non-null  float64\n",
      " 49  y                    20000 non-null  int64  \n",
      "dtypes: float64(5), int64(4), uint8(41)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "fdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Imbalance\n",
    ">Before the model can be split into train and test datasets, the dataset needs to be assessed for imbalance. If the dataset is imbalanced, then it may be difficult to predict the target variable in a meaningful way using traditional scoring techniques. Another name for this type of issue in a classification model is rare event prediction. Imbalance can be expressed as a simple ratio. Technically, anything other than equal representation is considered imbalanced, but slight imbalance is not a significant problem. For our purposes, a ratio less than 0.2 will be considered imbalanced. In other words, if less than 20% of the observations in our dataset have a value of 'yes' or 1 in the target column, then the dataset will be considered significantly imbalanced and adjustments will be necessary.<br><br>\n",
    "In order to adjust for imbalance, a different scoring method will be used to assess each model. The roc_auc_score method will be used because it accounts for recall and the FPR (False Positive Rate). It is important to maximize the recall in whatever model is finally selected because it will ensure that a sufficient number of the most likely customers to subscribe to a term deposit are marketed to. The recall measures how many out of all of the positive target variables are correctly calssified. Also, we want to minimize the FPR because it wastes the bank's money too market to those who are unlikely to subscribe to a term deposit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of y in fbf dataset:\n",
      "2141\n",
      "\n",
      "Ratio of y in the target column in fbf dataframe:\n",
      "0.10705\n"
     ]
    }
   ],
   "source": [
    "n_of_y = list(fdf['y']).count(1)\n",
    "tot = fdf.shape[0]\n",
    "ratio_of_y = n_of_y/tot\n",
    "print('Total number of y in fbf dataset:')\n",
    "print(n_of_y)\n",
    "print()\n",
    "print('Ratio of y in the target column in fbf dataframe:')\n",
    "print(ratio_of_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data to plot\n",
    "labels = 'no','yes'\n",
    "num_no = list(fdf['y']).count(0)\n",
    "num_yes = list(fdf['y']).count(1)\n",
    "sizes = [num_no,num_yes]\n",
    "colors = ['gold','lightskyblue']\n",
    "explode = (0.1, 0)  # explode 1st slice\n",
    "\n",
    "# Plot\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This dataset is significantly imbalanced, so adjustments will have to be made. Specifically, the scoring method used throughout this notebook for each classification model will be the roc_auc_score method in the sklearn package. This scoring method aims to maximize the recall, while minimizing the false positive rate. The interpretation of this for the bank is that this new scoring function will aim to minimize the number of customers who are marketed to who are unlikely to subscribe to a term deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test data split\n",
    ">The data will be split into train and test datasets that will be used for all of the models. <br><br>\n",
    "<b>Regularization:</b><br>\n",
    "Importantly, the MinMaxScaler() function will be applied to the data at the same time as the train/test split. The MinMaxScaler() function is a commonly used regularization function which transforms all variables in each column to a value between 0-1 relative to other values in that variable. Regularization is applied to ensure that every factor in the dataset is weighed equally when distance-based classification models are applied. In models like support vector machines, the distance between points matters as that is the technique used to classify the data. Furthermore, Regularization will not affect non-distance-based calssification models. Therefore, standardization of the data is a critical first step regardless of whether classification or regression models are employed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fdf['y']\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fdf.drop('y', axis=1)\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin.</th>\n",
       "      <th>blue-collar</th>\n",
       "      <th>entrepreneur</th>\n",
       "      <th>housemaid</th>\n",
       "      <th>management</th>\n",
       "      <th>retired</th>\n",
       "      <th>self-employed</th>\n",
       "      <th>services</th>\n",
       "      <th>student</th>\n",
       "      <th>technician</th>\n",
       "      <th>...</th>\n",
       "      <th>nonexistent</th>\n",
       "      <th>success</th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36094</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6343</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15636</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27236</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16091</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19389</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29758</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20902</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       admin.  blue-collar  entrepreneur  housemaid  management  retired  \\\n",
       "36094       1            0             0          0           0        0   \n",
       "6343        0            1             0          0           0        0   \n",
       "15636       0            1             0          0           0        0   \n",
       "2710        0            0             0          0           1        0   \n",
       "27236       0            0             0          0           0        0   \n",
       "...       ...          ...           ...        ...         ...      ...   \n",
       "16091       0            0             0          0           0        0   \n",
       "19389       1            0             0          0           0        0   \n",
       "29758       0            1             0          0           0        0   \n",
       "30138       0            0             0          0           0        1   \n",
       "20902       1            0             0          0           0        0   \n",
       "\n",
       "       self-employed  services  student  technician  ...  nonexistent  \\\n",
       "36094              0         0        0           0  ...            1   \n",
       "6343               0         0        0           0  ...            1   \n",
       "15636              0         0        0           0  ...            1   \n",
       "2710               0         0        0           0  ...            1   \n",
       "27236              0         0        0           1  ...            1   \n",
       "...              ...       ...      ...         ...  ...          ...   \n",
       "16091              1         0        0           0  ...            1   \n",
       "19389              0         0        0           0  ...            1   \n",
       "29758              0         0        0           0  ...            1   \n",
       "30138              0         0        0           0  ...            0   \n",
       "20902              0         0        0           0  ...            1   \n",
       "\n",
       "       success   age  default  housing  loan  duration  campaign  pdays  \\\n",
       "36094        0  51.0        0        0     0      91.0       1.0  999.0   \n",
       "6343         0  32.0        0        1     0      72.0       2.0  999.0   \n",
       "15636        0  50.0        0        1     1     140.0       1.0  999.0   \n",
       "2710         0  50.0        0        0     0      72.0       7.0  999.0   \n",
       "27236        0  34.0        0        0     0     316.0       3.0  999.0   \n",
       "...        ...   ...      ...      ...   ...       ...       ...    ...   \n",
       "16091        0  38.0        0        0     0     843.0       8.0  999.0   \n",
       "19389        0  34.0        0        0     0     147.0       1.0  999.0   \n",
       "29758        0  34.0        0        0     0      86.0       2.0  999.0   \n",
       "30138        0  59.0        0        1     0     968.0       1.0    5.0   \n",
       "20902        0  34.0        0        0     0     260.0       6.0  999.0   \n",
       "\n",
       "       previous  \n",
       "36094       0.0  \n",
       "6343        0.0  \n",
       "15636       0.0  \n",
       "2710        0.0  \n",
       "27236       0.0  \n",
       "...         ...  \n",
       "16091       0.0  \n",
       "19389       0.0  \n",
       "29758       0.0  \n",
       "30138       2.0  \n",
       "20902       0.0  \n",
       "\n",
       "[20000 rows x 49 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The dependent variables and the target variable columns have been separated into two datasets. When the data is split into train/test sets, observations will be randomly selected for each, therefore ensuring the train/test datasets accurately represent the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the data into train and test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, random_state = 0)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Data has now been preprocessed and is ready for ML Classification Algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Firstly we will use Voting Classififier algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting classifiers (hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(x_train,y_train)\n",
    "\n",
    "log_clf = LogisticRegression(solver='liblinear', random_state=0)\n",
    "log_clf.fit(x_train,y_train)\n",
    "\n",
    "linsvc = LinearSVC(random_state=0)\n",
    "linsvc.fit(x_train,y_train)\n",
    "\n",
    "svcr = SVC(kernel='rbf', random_state=0)\n",
    "svcr.fit(x_train,y_train)\n",
    "\n",
    "svcp = SVC(kernel='poly', random_state=0)\n",
    "svcp.fit(x_train,y_train)\n",
    "\n",
    "lsvc = SVC(kernel='linear', random_state=0)\n",
    "lsvc.fit(x_train,y_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC_AUC score of hard votingclassifier compared to individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.6172299184819934\n",
      "LinearSVC 0.6129890647362618\n",
      "KNeighborsClassifier 0.5795440034900035\n",
      "SVC 0.5954377388451004\n",
      "SVC 0.590296187058387\n",
      "SVC 0.5963259495697717\n",
      "DecisionTreeClassifier 0.6747005763097885\n",
      "VotingClassifier 0.5979021711414897\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('log_clf', log_clf),('linsvc',linsvc),\n",
    "                               ('knn_clf', knn_clf),('lsvc_clf',lsvc),('svcr', svcr),('svcp',svcp), ('tree',tree)],voting='hard')\n",
    "voting_clf.fit(x_train, y_train)\n",
    "voting_clf.fit(x_train, y_train)\n",
    "algo=[]\n",
    "score=[]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf,linsvc, knn_clf, lsvc,svcr, svcp,tree,voting_clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print((clf.__class__.__name__), roc_auc_score(y_test, y_pred))\n",
    "    algo.append(clf)\n",
    "    score.append(roc_auc_score(y_test, y_pred))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "algo=['log_clf','linsvc', 'knn_clf', 'lsvc', 'svcr', 'svcp','tree','voting_clf']\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(algo,score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft voting classifiers  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(x_train,y_train)\n",
    "\n",
    "log_clf = LogisticRegression(solver='liblinear', random_state=0)\n",
    "log_clf.fit(x_train,y_train)\n",
    "\n",
    "lsvc = LinearSVC(random_state=0)\n",
    "lsvc.fit(x_train,y_train)\n",
    "\n",
    "svcr = SVC(probability=True,kernel='rbf', random_state=0)\n",
    "svcr.fit(x_train,y_train)\n",
    "\n",
    "svcp = SVC(probability=True,kernel='poly')\n",
    "svcp.fit(x_train,y_train)\n",
    "\n",
    "lsvc = SVC(probability=True,kernel='linear', random_state=0)\n",
    "lsvc.fit(x_train,y_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC socre of soft votingclassifier compared to individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.6172299184819934\n",
      "KNeighborsClassifier 0.5795440034900035\n",
      "SVC 0.5954377388451004\n",
      "SVC 0.590296187058387\n",
      "SVC 0.5963259495697717\n",
      "DecisionTreeClassifier 0.6747005763097885\n",
      "VotingClassifier 0.5993595617999298\n"
     ]
    }
   ],
   "source": [
    "\n",
    "voting_clf = VotingClassifier(estimators=[('log_clf', log_clf), ('knn_clf', knn_clf),('lsvc',lsvc),('svcr', svcr),('svcp',svcp),\n",
    "                                          ('tree',tree)], voting='soft')\n",
    "voting_clf.fit(x_train, y_train)\n",
    "\n",
    "score1=[]\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, lsvc,svcr, svcp,tree,voting_clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(clf.__class__.__name__, roc_auc_score(y_test, y_pred))\n",
    "    score1.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "algo=['log_clf','linsvc', 'knn_clf', 'lsvc,svcr', 'svcp','tree','voting_clf']\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(algo,score1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the bar diagram, we can see that individual decision tree have high ROC AUC score than soft voting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging classifier on LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8857314096724549"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "lsvc = LinearSVC(random_state=0)\n",
    "lsvc.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "bag_clf = BaggingClassifier(lsvc, random_state=0,n_jobs=-1)\n",
    "\n",
    "\n",
    "param_grid = {'max_samples': [0.01,0.05,0.1,0.5,1],\n",
    "\n",
    "              'max_features': [0.01,0.05,0.1,0.5,1]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(bag_clf, param_grid, cv=5,scoring = 'roc_auc')\n",
    "\n",
    "grid_search.fit(x_train,y_train)\n",
    "\n",
    "BaggingLinearSVC=grid_search.best_score_\n",
    "BaggingLinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging classifier on DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8422130104818379"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# next euta model, 2nd perform garne choose garera\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(x_train,y_train)\n",
    "\n",
    "bag_clf = BaggingClassifier(tree, random_state=0, n_jobs=-1)\n",
    "\n",
    "param_grid = {'max_samples': [0.01,0.05,0.1,0.5,1],\n",
    "\n",
    "              'max_features': [0.01,0.05,0.1,0.5,1]}\n",
    "\n",
    "grid_search = GridSearchCV(bag_clf, param_grid, cv=5,scoring = 'roc_auc')\n",
    "grid_search.fit(x_train,y_train)\n",
    "BaggingDecisionTreeClassifier=grid_search.best_score_\n",
    "BaggingDecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasting  on LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8869204754565194"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "lsvc = LinearSVC(random_state=0)\n",
    "lsvc.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "bag_clf = BaggingClassifier(lsvc, random_state=0,bootstrap=False, n_jobs=-1)\n",
    "\n",
    "\n",
    "param_grid = {'max_samples': [0.01,0.05,0.1,0.5,1],\n",
    "\n",
    "              'max_features': [0.01,0.05,0.1,0.5,1]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(bag_clf, param_grid, cv=5,scoring = 'roc_auc')\n",
    "\n",
    "grid_search.fit(x_train,y_train)\n",
    "PastingLinearSVC=grid_search.best_score_\n",
    "PastingLinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasting  on DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8425867935876339"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "bag_clf = BaggingClassifier(tree, random_state=0, n_jobs=-1,bootstrap=False,)\n",
    "\n",
    "\n",
    "param_grid = {'max_samples': [0.01,0.05,0.1,0.5,1],\n",
    "\n",
    "              'max_features': [0.01,0.05,0.1,0.5,1]}\n",
    "\n",
    "grid_search = GridSearchCV(bag_clf, param_grid, cv=5,scoring = 'roc_auc')\n",
    "\n",
    "grid_search.fit(x_train,y_train)\n",
    "PastingDecisionTreeClassifier=grid_search.best_score_\n",
    "PastingDecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboast on DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6733682602227817)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adaboast in decision tree\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score\n",
    "\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(random_state=0), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada_clf.fit(x_train, y_train)\n",
    "AdaboastDecisionTreeClassifier=roc_auc_score(y_train, ada_clf.predict(x_train))\n",
    "roc_auc_score(y_train, ada_clf.predict(x_train)),roc_auc_score(y_test, ada_clf.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboast on linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6217340840153018, 0.6156474532521201)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(LinearSVC(random_state=0), n_estimators=200, algorithm=\"SAMME\", learning_rate=0.5, random_state=0)\n",
    "ada_clf.fit(x_train, y_train)\n",
    "\n",
    "AdaboastlinearSVC=roc_auc_score(y_train, ada_clf.predict(x_train))\n",
    "roc_auc_score(y_train, ada_clf.predict(x_train)),roc_auc_score(y_test, ada_clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Bosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6879014999380986, 0.6547720279280843)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(x_train, y_train)\n",
    "\n",
    "Gradient_Bosting=roc_auc_score(y_train, gbrt.predict(x_train))\n",
    "roc_auc_score(y_train, gbrt.predict(x_train)),roc_auc_score(y_test, gbrt.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7fc9258d7430>,\n",
       "  <matplotlib.axis.YTick at 0x7fc9258d7070>,\n",
       "  <matplotlib.axis.YTick at 0x7fc9255172b0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc925010190>,\n",
       "  <matplotlib.axis.YTick at 0x7fc9250106a0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc925010bb0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc9250107f0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc925016100>,\n",
       "  <matplotlib.axis.YTick at 0x7fc925016610>,\n",
       "  <matplotlib.axis.YTick at 0x7fc925016b20>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92615a070>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92615a580>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92615aa90>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92615afa0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92615e4f0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92615ea00>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92615a250>,\n",
       "  <matplotlib.axis.YTick at 0x7fc9250162e0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92615e070>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92615ef10>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926165460>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926165970>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926165eb0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92616b400>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92616b910>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926165a60>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92615e100>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92616bc70>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92616bee0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926171430>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926171970>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926171e80>,\n",
       "  <matplotlib.axis.YTick at 0x7fc9261773d0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc9261778e0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926177df0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc9261775b0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926171640>,\n",
       "  <matplotlib.axis.YTick at 0x7fc925010400>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92617c340>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92617c850>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92617cd60>,\n",
       "  <matplotlib.axis.YTick at 0x7fc9261822b0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc9261827c0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926182cd0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926188220>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926182400>,\n",
       "  <matplotlib.axis.YTick at 0x7fc92617c490>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926171ac0>,\n",
       "  <matplotlib.axis.YTick at 0x7fc926188790>],\n",
       " [Text(0, 0, 'admin.'),\n",
       "  Text(0, 0, 'blue-collar'),\n",
       "  Text(0, 0, 'entrepreneur'),\n",
       "  Text(0, 0, 'housemaid'),\n",
       "  Text(0, 0, 'management'),\n",
       "  Text(0, 0, 'retired'),\n",
       "  Text(0, 0, 'self-employed'),\n",
       "  Text(0, 0, 'services'),\n",
       "  Text(0, 0, 'student'),\n",
       "  Text(0, 0, 'technician'),\n",
       "  Text(0, 0, 'unemployed'),\n",
       "  Text(0, 0, 'divorced'),\n",
       "  Text(0, 0, 'married'),\n",
       "  Text(0, 0, 'single'),\n",
       "  Text(0, 0, 'basic.4y'),\n",
       "  Text(0, 0, 'basic.6y'),\n",
       "  Text(0, 0, 'basic.9y'),\n",
       "  Text(0, 0, 'high.school'),\n",
       "  Text(0, 0, 'illiterate'),\n",
       "  Text(0, 0, 'professional.course'),\n",
       "  Text(0, 0, 'university.degree'),\n",
       "  Text(0, 0, 'cellular'),\n",
       "  Text(0, 0, 'telephone'),\n",
       "  Text(0, 0, 'apr'),\n",
       "  Text(0, 0, 'aug'),\n",
       "  Text(0, 0, 'dec'),\n",
       "  Text(0, 0, 'jul'),\n",
       "  Text(0, 0, 'jun'),\n",
       "  Text(0, 0, 'mar'),\n",
       "  Text(0, 0, 'may'),\n",
       "  Text(0, 0, 'nov'),\n",
       "  Text(0, 0, 'oct'),\n",
       "  Text(0, 0, 'sep'),\n",
       "  Text(0, 0, 'fri'),\n",
       "  Text(0, 0, 'mon'),\n",
       "  Text(0, 0, 'thu'),\n",
       "  Text(0, 0, 'tue'),\n",
       "  Text(0, 0, 'wed'),\n",
       "  Text(0, 0, 'failure'),\n",
       "  Text(0, 0, 'nonexistent'),\n",
       "  Text(0, 0, 'success'),\n",
       "  Text(0, 0, 'age'),\n",
       "  Text(0, 0, 'default'),\n",
       "  Text(0, 0, 'housing'),\n",
       "  Text(0, 0, 'loan'),\n",
       "  Text(0, 0, 'duration'),\n",
       "  Text(0, 0, 'campaign'),\n",
       "  Text(0, 0, 'pdays'),\n",
       "  Text(0, 0, 'previous')])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.subplots(figsize = (20,10))\n",
    "y_list = gbrt.feature_importances_\n",
    "y_pos = np.arange(len(y_list))\n",
    "features = x.columns\n",
    "plt.barh(y_pos, y_list, align='center', alpha=0.4)\n",
    "plt.yticks(y_pos, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The results of above algorithms are presented in the table below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training_ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaggingLinearSVC</th>\n",
       "      <td>0.885731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingDecisionTreeClassifier</th>\n",
       "      <td>0.842213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PastingLinearSVC</th>\n",
       "      <td>0.886920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PastingDecisionTreeClassifier</th>\n",
       "      <td>0.842587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaboastDecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaboastlinearSVC</th>\n",
       "      <td>0.621734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient_Bosting</th>\n",
       "      <td>0.687901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Training_ROC_AUC\n",
       "BaggingLinearSVC                        0.885731\n",
       "BaggingDecisionTreeClassifier           0.842213\n",
       "PastingLinearSVC                        0.886920\n",
       "PastingDecisionTreeClassifier           0.842587\n",
       "AdaboastDecisionTreeClassifier          1.000000\n",
       "AdaboastlinearSVC                       0.621734\n",
       "Gradient_Bosting                        0.687901"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=['BaggingLinearSVC','BaggingDecisionTreeClassifier','PastingLinearSVC','PastingDecisionTreeClassifier','AdaboastDecisionTreeClassifier','AdaboastlinearSVC','Gradient_Bosting']\n",
    "b=(BaggingLinearSVC,BaggingDecisionTreeClassifier,PastingLinearSVC,PastingDecisionTreeClassifier,AdaboastDecisionTreeClassifier,AdaboastlinearSVC,Gradient_Bosting)\n",
    "ab=pd.DataFrame(b,a)\n",
    "ab.columns=['Training_ROC_AUC']\n",
    "ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Although these models gave us really high ROC_AUC, but these models are overfiitted and perform really bad in test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing data with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pca = PCA(n_components=0.95)\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models:\n",
    "##### Models Used: \n",
    ">KNN classification, Logistic Regression, Linear Support Vector Machine (SVM), Kernelized Support Vector Machine (rbf, poly, and linear), and Decision Tree Classifier. <br> <br>\n",
    ">Intermediate models will be chosen based on maximizing the test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we will run all the individual classification model using reduced data from PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': [5, 10, 15, 20, 30, 40, 50]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#best implementation\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': [5, 10, 15, 20, 30, 40, 50]}\n",
    "knn_grid = GridSearchCV(knn, param_grid, cv = 5, n_jobs = -1, scoring = 'roc_auc')\n",
    "knn_grid.fit(x_train, y_train) #imbalance X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 50}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc926227490>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=knn_grid.cv_results_\n",
    "y=a['mean_test_score']\n",
    "x=[5, 10, 15, 20, 30, 40, 50]\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the figure as well, we can see the best param is when k=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': [5, 10, 15, 20, 30, 40, 50]},\n",
       "             scoring='roc_auc')>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(random_state=0, solver='liblinear'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'max_iter': [50, 100, 500, 1000]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'max_iter': [50,100,500,1000]}\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "logreg_grid = GridSearchCV(logreg, param_grid, cv = 5, n_jobs = -1, scoring = 'roc_auc')\n",
    "logreg_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'max_iter': 50}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7385643333477241\n"
     ]
    }
   ],
   "source": [
    "logreg_score = logreg_grid.best_score_\n",
    "print(logreg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas series to numpy arrays for use in following models\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7452091454070082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "lsvc = LinearSVC(random_state=0)\n",
    "\n",
    "param_grid = {'C': [.001,.01,.1,1,10,100]}\n",
    "\n",
    "lsvc_grid = GridSearchCV(lsvc, cv = 5, param_grid=param_grid, n_jobs = -1, scoring = 'roc_auc')\n",
    "lsvc_grid.fit(x_train, y_train)\n",
    "\n",
    "lsvm_score = lsvc_grid.best_score_\n",
    "print(lsvm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernelized SVM - rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7418919574243988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [.001,.01,.1,1,10,100], 'gamma': [.001,.01,.1,1,10,100]}\n",
    "\n",
    "svcr = SVC(kernel='rbf', random_state=0)\n",
    "\n",
    "svcr_grid = GridSearchCV(svcr, cv=5, param_grid=param_grid, n_jobs=-1, scoring = 'roc_auc')\n",
    "\n",
    "svcr_grid.fit(x_train, y_train)\n",
    "\n",
    "rsvc_score = svcr_grid.best_score_\n",
    "print(rsvc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.001}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcr_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernelized SVM - poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6848198928554332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [.1,1,10,100]}\n",
    "\n",
    "svcp = SVC(kernel='poly', degree=3, random_state=0, coef0=1)\n",
    "\n",
    "svcp_grid = GridSearchCV(svcp, cv=5, param_grid=param_grid, n_jobs=-1, scoring = 'roc_auc')\n",
    "\n",
    "svcp_grid.fit(x_train, y_train)\n",
    "\n",
    "psvc_score = svcp_grid.best_score_\n",
    "print(psvc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcp_grid.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernelized SVM - linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='linear', random_state=0), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100]}, scoring='roc_auc')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [.1,1,10,100]}\n",
    "\n",
    "lsvc = SVC(kernel='linear', random_state=0)\n",
    "\n",
    "lsvc_grid = GridSearchCV(lsvc, cv=5, param_grid=param_grid, n_jobs=-1, scoring = 'roc_auc')\n",
    "\n",
    "lsvc_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7359422641368759\n"
     ]
    }
   ],
   "source": [
    "lsvc_score = lsvc_grid.best_score_\n",
    "print(lsvc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid={'max_depth': [20, 30, 40, 50, 60, 70],\n",
       "                         'min_impurity_decrease': [0.001, 0.005, 0.01, 0.05,\n",
       "                                                   0.1],\n",
       "                         'min_samples_leaf': [30, 60, 120, 240, 480],\n",
       "                         'min_samples_split': [30, 60, 120, 240, 480]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "midlst= [.001,.005,.01,.05,.1] # these numbers are relatively arbitrary\n",
    "msllst= [30,60,120,240,480] # below a sample of size n=30 is not significant enough to justify its own leaf\n",
    "msslst= [30,60,120,240,480] \n",
    "mdlst= [20,30,40,50,60,70] # too large of a tree will lose its interpretability, and therefore its business value. May consider further trimming.\n",
    "\n",
    "param_grid = {'min_impurity_decrease': midlst, 'min_samples_leaf': msllst, 'min_samples_split': msslst, 'max_depth': mdlst}\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree_grid = GridSearchCV(tree, param_grid=param_grid, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "tree_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7026723127386888\n"
     ]
    }
   ],
   "source": [
    "dtree_score = tree_grid.best_score_\n",
    "print(dtree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'min_impurity_decrease': 0.001,\n",
       " 'min_samples_leaf': 120,\n",
       " 'min_samples_split': 30}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Without_PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn_score</th>\n",
       "      <td>0.785281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg_score</th>\n",
       "      <td>0.891234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsvm_score</th>\n",
       "      <td>0.893031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsvc_score</th>\n",
       "      <td>0.875116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rsvc_score</th>\n",
       "      <td>0.887966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psvc_score</th>\n",
       "      <td>0.875116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsvc</th>\n",
       "      <td>0.888594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtree_score</th>\n",
       "      <td>0.830254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Without_PCA\n",
       "knn_score        0.785281\n",
       "logreg_score     0.891234\n",
       "lsvm_score       0.893031\n",
       "lsvc_score       0.875116\n",
       "rsvc_score       0.887966\n",
       "psvc_score       0.875116\n",
       "lsvc             0.888594\n",
       "dtree_score      0.830254"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"knn_score\": 0.785281, \"logreg_score\": 0.891234, \"lsvm_score\": 0.893031,\"lsvc_score\":0.888594,\"rsvc_score\":0.887966\n",
    "     ,\"psvc_score\": 0.875116,\"lsvc_score\": 0.875116,\"lsvc\":0.888594,\"dtree_score\":0.830254}\n",
    "\n",
    "import pandas as pd\n",
    "d=pd.Series(d)\n",
    "Project1result=d.to_frame()\n",
    "Project1result\n",
    "Project1result.columns=['Without_PCA']\n",
    "Project1result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras\n",
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine x & y\n",
    "y = fdf['y']\n",
    "#y\n",
    "x = fdf.drop('y', axis=1)\n",
    "#x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=0)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=49, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1500/1500 [==============================] - 1s 616us/step - loss: 0.3820 - accuracy: 0.8434\n",
      "Epoch 2/150\n",
      "1500/1500 [==============================] - 1s 652us/step - loss: 0.2509 - accuracy: 0.9046\n",
      "Epoch 3/150\n",
      "1500/1500 [==============================] - 1s 621us/step - loss: 0.2291 - accuracy: 0.9073\n",
      "Epoch 4/150\n",
      "1500/1500 [==============================] - 1s 602us/step - loss: 0.2250 - accuracy: 0.9054\n",
      "Epoch 5/150\n",
      "1500/1500 [==============================] - 1s 595us/step - loss: 0.2281 - accuracy: 0.9063\n",
      "Epoch 6/150\n",
      "1500/1500 [==============================] - 1s 608us/step - loss: 0.2216 - accuracy: 0.9078\n",
      "Epoch 7/150\n",
      "1500/1500 [==============================] - 1s 590us/step - loss: 0.2132 - accuracy: 0.9118\n",
      "Epoch 8/150\n",
      "1500/1500 [==============================] - 1s 619us/step - loss: 0.2144 - accuracy: 0.9078\n",
      "Epoch 9/150\n",
      "1500/1500 [==============================] - 1s 583us/step - loss: 0.2161 - accuracy: 0.9097\n",
      "Epoch 10/150\n",
      "1500/1500 [==============================] - 1s 637us/step - loss: 0.2081 - accuracy: 0.9120\n",
      "Epoch 11/150\n",
      "1500/1500 [==============================] - 1s 677us/step - loss: 0.2186 - accuracy: 0.9089\n",
      "Epoch 12/150\n",
      "1500/1500 [==============================] - 1s 682us/step - loss: 0.2068 - accuracy: 0.9110\n",
      "Epoch 13/150\n",
      "1500/1500 [==============================] - 1s 757us/step - loss: 0.2102 - accuracy: 0.9117\n",
      "Epoch 14/150\n",
      "1500/1500 [==============================] - 1s 657us/step - loss: 0.2100 - accuracy: 0.9123\n",
      "Epoch 15/150\n",
      "1500/1500 [==============================] - 1s 703us/step - loss: 0.2059 - accuracy: 0.9128\n",
      "Epoch 16/150\n",
      "1500/1500 [==============================] - 1s 665us/step - loss: 0.2115 - accuracy: 0.9139\n",
      "Epoch 17/150\n",
      "1500/1500 [==============================] - 1s 701us/step - loss: 0.2079 - accuracy: 0.9136\n",
      "Epoch 18/150\n",
      "1500/1500 [==============================] - 1s 631us/step - loss: 0.2104 - accuracy: 0.9129\n",
      "Epoch 19/150\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 0.1999 - accuracy: 0.9170\n",
      "Epoch 20/150\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 0.2079 - accuracy: 0.9120\n",
      "Epoch 21/150\n",
      "1500/1500 [==============================] - 1s 836us/step - loss: 0.2027 - accuracy: 0.9160\n",
      "Epoch 22/150\n",
      "1500/1500 [==============================] - 1s 829us/step - loss: 0.2049 - accuracy: 0.9149\n",
      "Epoch 23/150\n",
      "1500/1500 [==============================] - 1s 657us/step - loss: 0.1986 - accuracy: 0.9157\n",
      "Epoch 24/150\n",
      "1500/1500 [==============================] - 1s 693us/step - loss: 0.2045 - accuracy: 0.9144\n",
      "Epoch 25/150\n",
      "1500/1500 [==============================] - 1s 683us/step - loss: 0.1962 - accuracy: 0.9193\n",
      "Epoch 26/150\n",
      "1500/1500 [==============================] - 1s 610us/step - loss: 0.2040 - accuracy: 0.9126\n",
      "Epoch 27/150\n",
      "1500/1500 [==============================] - 1s 645us/step - loss: 0.1908 - accuracy: 0.9198\n",
      "Epoch 28/150\n",
      "1500/1500 [==============================] - 1s 654us/step - loss: 0.1930 - accuracy: 0.9183\n",
      "Epoch 29/150\n",
      "1500/1500 [==============================] - 1s 697us/step - loss: 0.2025 - accuracy: 0.9137\n",
      "Epoch 30/150\n",
      "1500/1500 [==============================] - 1s 664us/step - loss: 0.1932 - accuracy: 0.9207\n",
      "Epoch 31/150\n",
      "1500/1500 [==============================] - 1s 642us/step - loss: 0.1959 - accuracy: 0.9185\n",
      "Epoch 32/150\n",
      "1500/1500 [==============================] - 1s 662us/step - loss: 0.1940 - accuracy: 0.9202\n",
      "Epoch 33/150\n",
      "1500/1500 [==============================] - 1s 666us/step - loss: 0.1954 - accuracy: 0.9196\n",
      "Epoch 34/150\n",
      "1500/1500 [==============================] - 1s 689us/step - loss: 0.1989 - accuracy: 0.9209\n",
      "Epoch 35/150\n",
      "1500/1500 [==============================] - 1s 698us/step - loss: 0.2003 - accuracy: 0.9159\n",
      "Epoch 36/150\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 0.1982 - accuracy: 0.9150\n",
      "Epoch 37/150\n",
      "1500/1500 [==============================] - 1s 674us/step - loss: 0.1960 - accuracy: 0.9199\n",
      "Epoch 38/150\n",
      "1500/1500 [==============================] - 1s 688us/step - loss: 0.2050 - accuracy: 0.9133\n",
      "Epoch 39/150\n",
      "1500/1500 [==============================] - 1s 689us/step - loss: 0.1963 - accuracy: 0.9184\n",
      "Epoch 40/150\n",
      "1500/1500 [==============================] - 1s 680us/step - loss: 0.1921 - accuracy: 0.9171\n",
      "Epoch 41/150\n",
      "1500/1500 [==============================] - 1s 682us/step - loss: 0.1950 - accuracy: 0.9208\n",
      "Epoch 42/150\n",
      "1500/1500 [==============================] - 1s 682us/step - loss: 0.1961 - accuracy: 0.9193\n",
      "Epoch 43/150\n",
      "1500/1500 [==============================] - 1s 695us/step - loss: 0.2021 - accuracy: 0.9147\n",
      "Epoch 44/150\n",
      "1500/1500 [==============================] - 1s 695us/step - loss: 0.1901 - accuracy: 0.9209\n",
      "Epoch 45/150\n",
      "1500/1500 [==============================] - 1s 667us/step - loss: 0.1980 - accuracy: 0.9196\n",
      "Epoch 46/150\n",
      "1500/1500 [==============================] - 1s 680us/step - loss: 0.1935 - accuracy: 0.9174\n",
      "Epoch 47/150\n",
      "1500/1500 [==============================] - 1s 665us/step - loss: 0.1895 - accuracy: 0.9193\n",
      "Epoch 48/150\n",
      "1500/1500 [==============================] - 1s 672us/step - loss: 0.1965 - accuracy: 0.9170\n",
      "Epoch 49/150\n",
      "1500/1500 [==============================] - 1s 635us/step - loss: 0.1952 - accuracy: 0.9154\n",
      "Epoch 50/150\n",
      "1500/1500 [==============================] - 1s 659us/step - loss: 0.1943 - accuracy: 0.9209\n",
      "Epoch 51/150\n",
      "1500/1500 [==============================] - 1s 641us/step - loss: 0.1939 - accuracy: 0.9191\n",
      "Epoch 52/150\n",
      "1500/1500 [==============================] - 1s 683us/step - loss: 0.1961 - accuracy: 0.9181\n",
      "Epoch 53/150\n",
      "1500/1500 [==============================] - 1s 606us/step - loss: 0.1911 - accuracy: 0.9206\n",
      "Epoch 54/150\n",
      "1500/1500 [==============================] - 1s 602us/step - loss: 0.1954 - accuracy: 0.9197\n",
      "Epoch 55/150\n",
      "1500/1500 [==============================] - 1s 589us/step - loss: 0.1942 - accuracy: 0.9179\n",
      "Epoch 56/150\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 0.1945 - accuracy: 0.9182\n",
      "Epoch 57/150\n",
      "1500/1500 [==============================] - 1s 689us/step - loss: 0.1932 - accuracy: 0.9181\n",
      "Epoch 58/150\n",
      "1500/1500 [==============================] - 1s 609us/step - loss: 0.1877 - accuracy: 0.9202\n",
      "Epoch 59/150\n",
      "1500/1500 [==============================] - 1s 633us/step - loss: 0.1923 - accuracy: 0.9186\n",
      "Epoch 60/150\n",
      "1500/1500 [==============================] - 1s 611us/step - loss: 0.1870 - accuracy: 0.9210\n",
      "Epoch 61/150\n",
      "1500/1500 [==============================] - 1s 613us/step - loss: 0.1967 - accuracy: 0.9161\n",
      "Epoch 62/150\n",
      "1500/1500 [==============================] - 1s 601us/step - loss: 0.1851 - accuracy: 0.9233\n",
      "Epoch 63/150\n",
      "1500/1500 [==============================] - 1s 618us/step - loss: 0.1884 - accuracy: 0.9202\n",
      "Epoch 64/150\n",
      "1500/1500 [==============================] - 1s 659us/step - loss: 0.1901 - accuracy: 0.9185\n",
      "Epoch 65/150\n",
      "1500/1500 [==============================] - 1s 628us/step - loss: 0.1927 - accuracy: 0.9183\n",
      "Epoch 66/150\n",
      "1500/1500 [==============================] - 1s 632us/step - loss: 0.1975 - accuracy: 0.9166\n",
      "Epoch 67/150\n",
      "1500/1500 [==============================] - 1s 972us/step - loss: 0.1898 - accuracy: 0.9205\n",
      "Epoch 68/150\n",
      "1500/1500 [==============================] - 1s 588us/step - loss: 0.1935 - accuracy: 0.9179\n",
      "Epoch 69/150\n",
      "1500/1500 [==============================] - 1s 663us/step - loss: 0.1959 - accuracy: 0.9155\n",
      "Epoch 70/150\n",
      "1500/1500 [==============================] - 1s 640us/step - loss: 0.1878 - accuracy: 0.9218\n",
      "Epoch 71/150\n",
      "1500/1500 [==============================] - 1s 594us/step - loss: 0.1868 - accuracy: 0.9219\n",
      "Epoch 72/150\n",
      "1500/1500 [==============================] - 1s 659us/step - loss: 0.1851 - accuracy: 0.9217\n",
      "Epoch 73/150\n",
      "1500/1500 [==============================] - 1s 759us/step - loss: 0.1903 - accuracy: 0.9185\n",
      "Epoch 74/150\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.1889 - accuracy: 0.9223\n",
      "Epoch 75/150\n",
      "1500/1500 [==============================] - 1s 698us/step - loss: 0.1951 - accuracy: 0.9156\n",
      "Epoch 76/150\n",
      "1500/1500 [==============================] - 1s 718us/step - loss: 0.1910 - accuracy: 0.9190\n",
      "Epoch 77/150\n",
      "1500/1500 [==============================] - 1s 729us/step - loss: 0.1939 - accuracy: 0.9179\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 706us/step - loss: 0.1948 - accuracy: 0.9142\n",
      "Epoch 79/150\n",
      "1500/1500 [==============================] - 1s 657us/step - loss: 0.1889 - accuracy: 0.9186\n",
      "Epoch 80/150\n",
      "1500/1500 [==============================] - 1s 660us/step - loss: 0.1845 - accuracy: 0.9200\n",
      "Epoch 81/150\n",
      "1500/1500 [==============================] - 1s 614us/step - loss: 0.1784 - accuracy: 0.9241\n",
      "Epoch 82/150\n",
      "1500/1500 [==============================] - 1s 584us/step - loss: 0.1882 - accuracy: 0.9198\n",
      "Epoch 83/150\n",
      "1500/1500 [==============================] - 1s 611us/step - loss: 0.1911 - accuracy: 0.9181\n",
      "Epoch 84/150\n",
      "1500/1500 [==============================] - 1s 619us/step - loss: 0.1904 - accuracy: 0.9196\n",
      "Epoch 85/150\n",
      "1500/1500 [==============================] - 1s 580us/step - loss: 0.1946 - accuracy: 0.9167\n",
      "Epoch 86/150\n",
      "1500/1500 [==============================] - 1s 595us/step - loss: 0.1924 - accuracy: 0.9192\n",
      "Epoch 87/150\n",
      "1500/1500 [==============================] - 1s 621us/step - loss: 0.1863 - accuracy: 0.9239\n",
      "Epoch 88/150\n",
      "1500/1500 [==============================] - 1s 620us/step - loss: 0.1876 - accuracy: 0.9216\n",
      "Epoch 89/150\n",
      "1500/1500 [==============================] - 1s 621us/step - loss: 0.1874 - accuracy: 0.9213\n",
      "Epoch 90/150\n",
      "1500/1500 [==============================] - 1s 586us/step - loss: 0.1885 - accuracy: 0.9195\n",
      "Epoch 91/150\n",
      "1500/1500 [==============================] - 1s 596us/step - loss: 0.1826 - accuracy: 0.9243\n",
      "Epoch 92/150\n",
      "1500/1500 [==============================] - 1s 569us/step - loss: 0.1898 - accuracy: 0.9213\n",
      "Epoch 93/150\n",
      "1500/1500 [==============================] - 1s 576us/step - loss: 0.1871 - accuracy: 0.9196\n",
      "Epoch 94/150\n",
      "1500/1500 [==============================] - 1s 602us/step - loss: 0.1840 - accuracy: 0.9237\n",
      "Epoch 95/150\n",
      "1500/1500 [==============================] - 1s 648us/step - loss: 0.1777 - accuracy: 0.9234\n",
      "Epoch 96/150\n",
      "1500/1500 [==============================] - 1s 600us/step - loss: 0.1854 - accuracy: 0.9185\n",
      "Epoch 97/150\n",
      "1500/1500 [==============================] - 1s 632us/step - loss: 0.1920 - accuracy: 0.9175\n",
      "Epoch 98/150\n",
      "1500/1500 [==============================] - 1s 654us/step - loss: 0.1777 - accuracy: 0.92420s - loss: 0.1737 - ac\n",
      "Epoch 99/150\n",
      "1500/1500 [==============================] - 1s 654us/step - loss: 0.1812 - accuracy: 0.9242\n",
      "Epoch 100/150\n",
      "1500/1500 [==============================] - 1s 664us/step - loss: 0.1889 - accuracy: 0.9186\n",
      "Epoch 101/150\n",
      "1500/1500 [==============================] - 1s 624us/step - loss: 0.1854 - accuracy: 0.9223\n",
      "Epoch 102/150\n",
      "1500/1500 [==============================] - 1s 600us/step - loss: 0.1894 - accuracy: 0.9196\n",
      "Epoch 103/150\n",
      "1500/1500 [==============================] - 1s 575us/step - loss: 0.1821 - accuracy: 0.9211\n",
      "Epoch 104/150\n",
      "1500/1500 [==============================] - 1s 602us/step - loss: 0.1881 - accuracy: 0.9191\n",
      "Epoch 105/150\n",
      "1500/1500 [==============================] - 1s 722us/step - loss: 0.1901 - accuracy: 0.9173\n",
      "Epoch 106/150\n",
      "1500/1500 [==============================] - 1s 648us/step - loss: 0.1859 - accuracy: 0.9205\n",
      "Epoch 107/150\n",
      "1500/1500 [==============================] - 1s 653us/step - loss: 0.1757 - accuracy: 0.9260\n",
      "Epoch 108/150\n",
      "1500/1500 [==============================] - 1s 635us/step - loss: 0.1872 - accuracy: 0.9164\n",
      "Epoch 109/150\n",
      "1500/1500 [==============================] - 1s 687us/step - loss: 0.1893 - accuracy: 0.9204\n",
      "Epoch 110/150\n",
      "1500/1500 [==============================] - 1s 654us/step - loss: 0.1924 - accuracy: 0.9159\n",
      "Epoch 111/150\n",
      "1500/1500 [==============================] - 1s 603us/step - loss: 0.1859 - accuracy: 0.9209\n",
      "Epoch 112/150\n",
      "1500/1500 [==============================] - 1s 671us/step - loss: 0.1887 - accuracy: 0.9180\n",
      "Epoch 113/150\n",
      "1500/1500 [==============================] - 1s 844us/step - loss: 0.1922 - accuracy: 0.9196\n",
      "Epoch 114/150\n",
      "1500/1500 [==============================] - 1s 638us/step - loss: 0.1852 - accuracy: 0.9240\n",
      "Epoch 115/150\n",
      "1500/1500 [==============================] - 1s 665us/step - loss: 0.1834 - accuracy: 0.9236\n",
      "Epoch 116/150\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.1853 - accuracy: 0.9208\n",
      "Epoch 117/150\n",
      "1500/1500 [==============================] - 1s 622us/step - loss: 0.1903 - accuracy: 0.9194\n",
      "Epoch 118/150\n",
      "1500/1500 [==============================] - 1s 642us/step - loss: 0.1812 - accuracy: 0.9245\n",
      "Epoch 119/150\n",
      "1500/1500 [==============================] - 1s 596us/step - loss: 0.1833 - accuracy: 0.9190\n",
      "Epoch 120/150\n",
      "1500/1500 [==============================] - 1s 655us/step - loss: 0.1831 - accuracy: 0.9242\n",
      "Epoch 121/150\n",
      "1500/1500 [==============================] - 1s 588us/step - loss: 0.1852 - accuracy: 0.9207\n",
      "Epoch 122/150\n",
      "1500/1500 [==============================] - 1s 721us/step - loss: 0.1789 - accuracy: 0.9251\n",
      "Epoch 123/150\n",
      "1500/1500 [==============================] - 1s 668us/step - loss: 0.1854 - accuracy: 0.9218\n",
      "Epoch 124/150\n",
      "1500/1500 [==============================] - 1s 601us/step - loss: 0.1835 - accuracy: 0.9205\n",
      "Epoch 125/150\n",
      "1500/1500 [==============================] - 1s 582us/step - loss: 0.1842 - accuracy: 0.9196\n",
      "Epoch 126/150\n",
      "1500/1500 [==============================] - 1s 586us/step - loss: 0.1865 - accuracy: 0.9184\n",
      "Epoch 127/150\n",
      "1500/1500 [==============================] - 1s 584us/step - loss: 0.1808 - accuracy: 0.9245\n",
      "Epoch 128/150\n",
      "1500/1500 [==============================] - 1s 597us/step - loss: 0.1825 - accuracy: 0.9220\n",
      "Epoch 129/150\n",
      "1500/1500 [==============================] - 1s 594us/step - loss: 0.1886 - accuracy: 0.9220\n",
      "Epoch 130/150\n",
      "1500/1500 [==============================] - 1s 580us/step - loss: 0.1908 - accuracy: 0.9180\n",
      "Epoch 131/150\n",
      "1500/1500 [==============================] - 1s 598us/step - loss: 0.1865 - accuracy: 0.9198\n",
      "Epoch 132/150\n",
      "1500/1500 [==============================] - 1s 582us/step - loss: 0.1847 - accuracy: 0.9199\n",
      "Epoch 133/150\n",
      "1500/1500 [==============================] - 1s 571us/step - loss: 0.1852 - accuracy: 0.9224\n",
      "Epoch 134/150\n",
      "1500/1500 [==============================] - 1s 580us/step - loss: 0.1826 - accuracy: 0.9221\n",
      "Epoch 135/150\n",
      "1500/1500 [==============================] - 1s 628us/step - loss: 0.1852 - accuracy: 0.9219\n",
      "Epoch 136/150\n",
      "1500/1500 [==============================] - 1s 605us/step - loss: 0.1841 - accuracy: 0.9207\n",
      "Epoch 137/150\n",
      "1500/1500 [==============================] - 1s 597us/step - loss: 0.1769 - accuracy: 0.9254\n",
      "Epoch 138/150\n",
      "1500/1500 [==============================] - 1s 575us/step - loss: 0.1822 - accuracy: 0.9210\n",
      "Epoch 139/150\n",
      "1500/1500 [==============================] - 1s 575us/step - loss: 0.1858 - accuracy: 0.9227\n",
      "Epoch 140/150\n",
      "1500/1500 [==============================] - 1s 589us/step - loss: 0.1839 - accuracy: 0.9227\n",
      "Epoch 141/150\n",
      "1500/1500 [==============================] - 1s 583us/step - loss: 0.1797 - accuracy: 0.9248\n",
      "Epoch 142/150\n",
      "1500/1500 [==============================] - 1s 665us/step - loss: 0.1821 - accuracy: 0.9203\n",
      "Epoch 143/150\n",
      "1500/1500 [==============================] - 1s 614us/step - loss: 0.1942 - accuracy: 0.9171\n",
      "Epoch 144/150\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 0.1835 - accuracy: 0.9227\n",
      "Epoch 145/150\n",
      "1500/1500 [==============================] - 1s 799us/step - loss: 0.1849 - accuracy: 0.9235\n",
      "Epoch 146/150\n",
      "1500/1500 [==============================] - 1s 652us/step - loss: 0.1827 - accuracy: 0.9249\n",
      "Epoch 147/150\n",
      "1500/1500 [==============================] - 1s 661us/step - loss: 0.1824 - accuracy: 0.9217\n",
      "Epoch 148/150\n",
      "1500/1500 [==============================] - 1s 661us/step - loss: 0.1925 - accuracy: 0.9209\n",
      "Epoch 149/150\n",
      "1500/1500 [==============================] - 1s 678us/step - loss: 0.1849 - accuracy: 0.9215\n",
      "Epoch 150/150\n",
      "1500/1500 [==============================] - 1s 697us/step - loss: 0.1842 - accuracy: 0.9252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc92b9ae970>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 603us/step - loss: 0.2472 - accuracy: 0.9014\n",
      "\n",
      "accuracy: 90.14%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.9124827e-03],\n",
       "       [3.8733780e-03],\n",
       "       [1.7317235e-01],\n",
       "       ...,\n",
       "       [9.0127289e-03],\n",
       "       [6.9745593e-06],\n",
       "       [4.3539188e-05]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search on Deep Learning\n",
    "\n",
    "We can use GridSearchCV to find the best epochs and batche size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=49, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model, verbose = 0)\n",
    "\n",
    "param_grid = {'batch_size':[10,20,30,40] , 'epochs':[10, 50, 100]}\n",
    "grid_search = GridSearchCV(estimator= model, param_grid = param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_result = grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train,grid_search.predict(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Based on the maximum grid search roc_auc score, the  SVC with Kernel-'rbc' Model was the best performing model in correctly calssifying whether a potential customer would subscribe to a term deposit product or not. Therefore, this model will be the subject of further analysis and optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model -SVC with Kernel-'rbc' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Training of the final model will include the entire training dataset so the estimator will be as close as possible to the true parameter. Although the dataset is imbalanced, there are other means of improving the model using ROC curves which includes precision and recall metrics. Again, the scoring function used will be the roc_auc scoring method as it aims to minimize the number of false positives and maximize the number of true positives so that the bank does not waste more money marketing to those who are unlikely to subscribe to a term deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we will used the best hyperparameter we found for Linear SVC on the entire training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best_model = SVC(kernel='rbf',**svcr_grid.best_params_,random_state=0)\n",
    "\n",
    "best_model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "roc_auc_score(y_train, best_model.decision_function(x_train))\n",
    "#roc_auc_score(y_train, best_model.predict(x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, best_model.decision_function(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, label=\"C={:.3f}\".format(0.1))\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "close_max = np.argmax(np.abs(thresholds))\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(best_model.decision_function(x_test) > -1, 1, 0)\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conclusion: Depending upon the business context, we can use different thresholds to either lower false positives or false negatives. With our threashold, Approximately 77% of the total number of those who would subscribe for a term deposit are correctly classified, but out of 100 people that the model predicts to be future subscibers, only 40% actually subscribe. Without information regarding the cost to send targeted ads and the profit from a term deposit subscriber, it is difficult to say if this model should be used to target the potential customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
